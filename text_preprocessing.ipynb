{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7af8382",
   "metadata": {},
   "source": [
    "# Text Preprocessing Techniques with Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c9ea3c",
   "metadata": {},
   "source": [
    "## 1. Lowercasing\n",
    "**Definition:** Converting all characters in text to lowercase to ensure uniformity. This helps avoid treating the same words as different due to case differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2894ee1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i love nlp! it's amazing ðŸ˜Š. check out https://example.com for more details. call me at +1-800-555-0199.\n"
     ]
    }
   ],
   "source": [
    "text = \"I love NLP! It's amazing ðŸ˜Š. Check out https://example.com for more details. Call me at +1-800-555-0199.\"\n",
    "text = text.lower()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a8b7ef",
   "metadata": {},
   "source": [
    "## 2. Tokenization\n",
    "**Definition:** Splitting text into smaller components such as words (word tokenization) or sentences (sentence tokenization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d719d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "tokens = word_tokenize(text)\n",
    "sentences = sent_tokenize(text)\n",
    "print(tokens)  \n",
    "# ['i', 'love', 'nlp', '!', 'it', \"'s\", 'amazing', 'ðŸ˜Š', '.', 'check', 'out', 'https', ':', '//example.com', 'for', 'more', 'details', '.', 'call', 'me', 'at', '+1-800-555-0199']\n",
    "print(sentences)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b145678",
   "metadata": {},
   "source": [
    "## 3. Stopword Removal\n",
    "**Definition:** Removing common words (like \"the,\" \"and,\" \"is\") that do not contribute much to the meaning of text but are frequent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1e8fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "print(filtered_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94155ded",
   "metadata": {},
   "source": [
    "## 4. Removing Punctuation\n",
    "**Definition:** Removing punctuation marks (like `.`, `!`, `,`) to clean up text data for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a1d9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "text_no_punct = text.translate(str.maketrans('', '', string.punctuation))\n",
    "print(text_no_punct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54897339",
   "metadata": {},
   "source": [
    "## 5. Removing Numbers\n",
    "**Definition:** Eliminating digits to reduce noise in the text, especially when numbers are not relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ec365e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "text_no_numbers = re.sub(r'\\d+', '', text)\n",
    "print(text_no_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f353a582",
   "metadata": {},
   "source": [
    "## 6. Stemming\n",
    "**Definition:** Reducing words to their root form by chopping off suffixes (e.g., \"playing\" becomes \"play\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734bddee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "stemmed_words = [stemmer.stem(word) for word in filtered_tokens]\n",
    "print(stemmed_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db707644",
   "metadata": {},
   "source": [
    "## 7. Lemmatization\n",
    "**Definition:** Reducing words to their base or dictionary form (e.g., \"running\" becomes \"run\"). Unlike stemming, it preserves the actual meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5d4659",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
    "print(lemmatized_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d51192c",
   "metadata": {},
   "source": [
    "## 8. Removing Extra Whitespaces\n",
    "**Definition:** Removing multiple spaces and replacing them with a single space for text uniformity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb91fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"I   love   NLP!  \"\n",
    "text_cleaned = \" \".join(text.split())\n",
    "print(text_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c78aa5",
   "metadata": {},
   "source": [
    "## 9. Removing URLs\n",
    "**Definition:** Eliminating website links from text to clean up irrelevant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7b84cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_no_urls = re.sub(r'http\\S+|www\\S+', '', text)\n",
    "print(text_no_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd3f00b",
   "metadata": {},
   "source": [
    "## 10. Removing HTML Tags\n",
    "**Definition:** Extracting only the visible text from HTML markup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9b7e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html_text = \"<p>Hello <b>World</b></p>\"\n",
    "clean_text = BeautifulSoup(html_text, \"html.parser\").get_text()\n",
    "print(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b93ed4",
   "metadata": {},
   "source": [
    "## 11. Spelling Correction\n",
    "**Definition:** Correcting misspelled words in text using context-based algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d01e4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "text_with_typos = \"I lov NLP!\"\n",
    "corrected_text = str(TextBlob(text_with_typos).correct())\n",
    "print(corrected_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d812f413",
   "metadata": {},
   "source": [
    "## 12. Removing Emojis\n",
    "**Definition:** Filtering out emojis and non-ASCII characters from text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83b6a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_no_emojis = re.sub(r'[^\u0000-]+', '', text)\n",
    "print(text_no_emojis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4ce8a6",
   "metadata": {},
   "source": [
    "## 13. Removing Special Characters\n",
    "**Definition:** Removing symbols or characters that don't contribute to the text's semantic meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946a123f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clean = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "print(text_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10378555",
   "metadata": {},
   "source": [
    "## 14. Part-of-Speech Tagging (POS)\n",
    "**Definition:** Assigning grammatical roles (like noun, verb, adjective) to each word in a text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf5f004",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag\n",
    "\n",
    "pos_tags = pos_tag(tokens)\n",
    "print(pos_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc29ad6e",
   "metadata": {},
   "source": [
    "## 15. Handling Contractions\n",
    "**Definition:** Expanding contractions (like \"don't\" to \"do not\") for clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc053d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contractions\n",
    "\n",
    "text_with_contractions = \"I'm happy. He doesn't like NLP.\"\n",
    "expanded_text = contractions.fix(text_with_contractions)\n",
    "print(expanded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3abff4d",
   "metadata": {},
   "source": [
    "## 16. Named Entity Recognition (NER)\n",
    "**Definition:** Identifying proper nouns and classifying them into categories such as persons, locations, or organizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa3c47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Barack Obama was born in Hawaii.\")\n",
    "entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "print(entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9377e587",
   "metadata": {},
   "source": [
    "## 17. Removing Accented Characters\n",
    "**Definition:** Normalizing characters with accents to plain ASCII characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ca8328",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "\n",
    "text_accented = \"cafÃ© naÃ¯ve rÃ©sumÃ©\"\n",
    "text_normalized = unicodedata.normalize('NFKD', text_accented).encode('ascii', 'ignore').decode('utf-8')\n",
    "print(text_normalized)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
